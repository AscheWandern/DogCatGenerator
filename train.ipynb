{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f39d753d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff983412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "from glob import glob\n",
    "from util import *\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from vae import VAE, ShallowVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6976008d",
   "metadata": {},
   "source": [
    "### Variables globales (argumentos) ((cambiarlo porque es un notebook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a38463",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch VAE')\n",
    "parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=20, metavar='N',\n",
    "                    help='number of epochs to train (default: 20)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=1, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    is_cuda = True\n",
    "else:\n",
    "    is_cuda = False\n",
    "\n",
    "BATCH_SIZE = args.batch_size\n",
    "EPOCH = args.epochs\n",
    "LOG_INTERVAL=args.log_interval\n",
    "path = '../PetImages/'\n",
    "kwargs = {'num_workers': 3, 'pin_memory': True} if is_cuda else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89878a03",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e34ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_transform = transforms.Compose([transforms.Resize((224,224))\n",
    "                                       ,transforms.ToTensor(), transforms.Normalize([0.48829153, 0.45526633, 0.41688013],[0.25974154, 0.25308523, 0.25552085])])\n",
    "train = ImageFolder(path+'train/',simple_transform)\n",
    "valid = ImageFolder(path+'valid/',simple_transform)\n",
    "train_data_gen = torch.utils.data.DataLoader(train,shuffle=True,batch_size=BATCH_SIZE,num_workers=kwargs['num_workers'])\n",
    "valid_data_gen = torch.utils.data.DataLoader(valid,batch_size=BATCH_SIZE,num_workers=kwargs['num_workers'])\n",
    "\n",
    "dataset_sizes = {'train':len(train_data_gen.dataset),'valid':len(valid_data_gen.dataset)}\n",
    "dataloaders = {'train':train_data_gen,'valid':valid_data_gen}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa80a3e6",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee50bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ShallowVAE(latent_variable_size=500, nc=3, ngf=224, ndf=224, is_cuda=is_cuda)\n",
    "\n",
    "#model = VAE(BasicBlock, [2, 2, 2, 2], latent_variable_size=500, nc=3, ngf=224, ndf=224, is_cuda=is_cuda)\n",
    "\n",
    "if is_cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "reconstruction_function = nn.MSELoss()\n",
    "reconstruction_function.size_average = False\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a7384",
   "metadata": {},
   "source": [
    "### Funcion de perdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283f2843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "\n",
    "    MSE = reconstruction_function(recon_x, x)\n",
    "\n",
    "    # https://arxiv.org/abs/1312.6114 (Appendix B)\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "\n",
    "    return MSE + KLD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f1c796",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff22b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    batch_idx = 1\n",
    "    for data in dataloaders['train']:\n",
    "        # get the inputs\n",
    "        inputs, _ = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(inputs)\n",
    "        #print(inputs.data.size())\n",
    "        inputs.data = unnormalize(inputs.data,[0.48829153, 0.45526633, 0.41688013],[0.25974154, 0.25308523, 0.25552085])\n",
    "\n",
    "        #print(\"input max/min\"+str(inputs.max())+\"  \"+str(inputs.min()))\n",
    "        #print(\"recon input max/min\"+str(recon_batch.max())+\"  \"+str(recon_batch.min()))\n",
    "        loss = loss_function(recon_batch, inputs, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(inputs), (len(dataloaders['train'])*128),\n",
    "                100. * batch_idx / len(dataloaders['train']),\n",
    "                loss.data[0] / len(inputs)))\n",
    "        batch_idx+=1\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / (len(dataloaders['train'])*BATCH_SIZE)))\n",
    "    return train_loss / (len(dataloaders['train'])*BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753a317",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for data in dataloaders['valid']:\n",
    "        # get the inputs\n",
    "        inputs, _ = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "        recon_batch, mu, logvar = model(inputs)\n",
    "        inputs.data = unnormalize(inputs.data,[0.48829153, 0.45526633, 0.41688013],[0.25974154, 0.25308523, 0.25552085])\n",
    "        test_loss += loss_function(recon_batch, inputs, mu, logvar).data[0]\n",
    "        if((epoch+1)%10==0):\n",
    "            torchvision.utils.save_image(inputs.data, './imgs/Epoch_{}_data.jpg'.format(epoch), nrow=8, padding=2)\n",
    "            torchvision.utils.save_image(recon_batch.data, './imgs/Epoch_{}_recon.jpg'.format(epoch), nrow=8, padding=2)\n",
    "\n",
    "    test_loss /= (len(dataloaders['valid'])*128)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "    return test_loss\n",
    "\n",
    "writer = SummaryWriter('runs/exp-1')\n",
    "since = time.time()\n",
    "for epoch in range(EPOCH):\n",
    "    train_loss = train(epoch)\n",
    "    test_loss = test(epoch)\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('test_loss',test_loss, epoch)\n",
    "    torch.save(model.state_dict(), './models/Epoch_{}_Train_loss_{:.4f}_Test_loss_{:.4f}.pth'.format(epoch, train_loss, test_loss))\n",
    "time_elapsed = time.time() - since    \n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
