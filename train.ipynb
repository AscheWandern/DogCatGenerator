{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f39d753d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff983412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "from glob import glob\n",
    "from util import *\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from vae import VAE, ShallowVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6976008d",
   "metadata": {},
   "source": [
    "### Variables globales (argumentos) ((cambiarlo porque es un notebook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a38463",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(1)\n",
    "    is_cuda = True\n",
    "else:\n",
    "    is_cuda = False\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCH = 20\n",
    "LOG_INTERVAL=1\n",
    "path = 'PetImages/'\n",
    "kwargs = {'num_workers': 3, 'pin_memory': True} if is_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c86c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editar estructura del dataset\n",
    "pathCat = path + 'Cat/'\n",
    "pathDog = path + 'Dog/'\n",
    "#os.mkdir(pathCat + 'valid')\n",
    "#os.mkdir(pathCat + 'train')\n",
    "#os.mkdir(pathDog + 'valid')\n",
    "#os.mkdir(pathDog + 'train')\n",
    "\n",
    "\n",
    "#for i in range(1250, 12500):\n",
    "#    shutil.copy(pathDog+'train/'+str(i)+'.jpg', path+'train/d' + str(i) + \".jpg\")\n",
    "#    shutil.copy(pathCat+'train/'+str(i)+'.jpg', path+'train/c' + str(i) + \".jpg\")\n",
    "\n",
    "\n",
    "for i in range(1250):\n",
    "    shutil.copy(pathDog+'valid/'+str(i)+'.jpg', path+'valid/d' + str(i) + \".jpg\")\n",
    "    shutil.copy(pathCat+'valid/'+str(i)+'.jpg', path+'valid/c' + str(i) + \".jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89878a03",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "531e34ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_transform = transforms.Compose([transforms.Resize((224,224))\n",
    "                                       ,transforms.ToTensor(), transforms.Normalize([0.48829153, 0.45526633, 0.41688013],[0.25974154, 0.25308523, 0.25552085])])\n",
    "train = ImageFolder(path+'train',simple_transform)\n",
    "valid = ImageFolder(path+'valid',simple_transform)\n",
    "train_data_gen = torch.utils.data.DataLoader(train,shuffle=True,batch_size=BATCH_SIZE,num_workers=kwargs['num_workers'])\n",
    "valid_data_gen = torch.utils.data.DataLoader(valid,batch_size=BATCH_SIZE,num_workers=kwargs['num_workers'])\n",
    "\n",
    "dataset_sizes = {'train':len(train_data_gen.dataset),'valid':len(valid_data_gen.dataset)}\n",
    "dataloaders = {'train':train_data_gen,'valid':valid_data_gen}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa80a3e6",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dee50bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ShallowVAE(latent_variable_size=500, nc=3, ngf=224, ndf=224, is_cuda=is_cuda)\n",
    "\n",
    "#model = VAE(BasicBlock, [2, 2, 2, 2], latent_variable_size=500, nc=3, ngf=224, ndf=224, is_cuda=is_cuda)\n",
    "\n",
    "if is_cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "reconstruction_function = nn.MSELoss()\n",
    "reconstruction_function.size_average = False\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a7384",
   "metadata": {},
   "source": [
    "### Funcion de perdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "283f2843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "\n",
    "    MSE = reconstruction_function(recon_x, x)\n",
    "\n",
    "    # https://arxiv.org/abs/1312.6114 (Appendix B)\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "\n",
    "    return MSE + KLD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f1c796",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ff22b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    batch_idx = 1\n",
    "    for data in dataloaders['train']:\n",
    "        # get the inputs\n",
    "        inputs, _ = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(inputs)\n",
    "        #print(inputs.data.size())\n",
    "        inputs.data = unnormalize(inputs.data,[0.48829153, 0.45526633, 0.41688013],[0.25974154, 0.25308523, 0.25552085])\n",
    "\n",
    "        #print(\"input max/min\"+str(inputs.max())+\"  \"+str(inputs.min()))\n",
    "        #print(\"recon input max/min\"+str(recon_batch.max())+\"  \"+str(recon_batch.min()))\n",
    "        loss = loss_function(recon_batch, inputs, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(inputs), (len(dataloaders['train'])*128),\n",
    "                100. * batch_idx / len(dataloaders['train']),\n",
    "                loss.data / len(inputs)))\n",
    "        batch_idx+=1\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / (len(dataloaders['train'])*BATCH_SIZE)))\n",
    "    return train_loss / (len(dataloaders['train'])*BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753a317",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54ab6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for data in dataloaders['valid']:\n",
    "        # get the inputs\n",
    "        inputs, _ = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "        recon_batch, mu, logvar = model(inputs)\n",
    "        inputs.data = unnormalize(inputs.data,[0.48829153, 0.45526633, 0.41688013],[0.25974154, 0.25308523, 0.25552085])\n",
    "        test_loss += loss_function(recon_batch, inputs, mu, logvar).data\n",
    "        if((epoch+1)%10==0):\n",
    "            torchvision.utils.save_image(inputs.data, './imgs/Epoch_{}_data.jpg'.format(epoch), nrow=8, padding=2)\n",
    "            torchvision.utils.save_image(recon_batch.data, './imgs/Epoch_{}_recon.jpg'.format(epoch), nrow=8, padding=2)\n",
    "\n",
    "    test_loss /= (len(dataloaders['valid'])*128)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "    return test_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d081748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [128/22528 (1%)]\tLoss: 442.437927\n",
      "Train Epoch: 0 [256/22528 (1%)]\tLoss: 295.717072\n",
      "Train Epoch: 0 [384/22528 (2%)]\tLoss: 184.538345\n",
      "Train Epoch: 0 [512/22528 (2%)]\tLoss: 126.672523\n",
      "Train Epoch: 0 [640/22528 (3%)]\tLoss: 85.740570\n",
      "Train Epoch: 0 [768/22528 (3%)]\tLoss: 57.926258\n",
      "Train Epoch: 0 [896/22528 (4%)]\tLoss: 39.310516\n",
      "Train Epoch: 0 [1024/22528 (5%)]\tLoss: 26.366573\n",
      "Train Epoch: 0 [1152/22528 (5%)]\tLoss: 19.974211\n",
      "Train Epoch: 0 [1280/22528 (6%)]\tLoss: 13.740553\n",
      "Train Epoch: 0 [1408/22528 (6%)]\tLoss: 9.046861\n",
      "Train Epoch: 0 [1536/22528 (7%)]\tLoss: 6.993788\n",
      "Train Epoch: 0 [1664/22528 (7%)]\tLoss: 4.703500\n",
      "Train Epoch: 0 [1792/22528 (8%)]\tLoss: 3.761890\n",
      "Train Epoch: 0 [1920/22528 (9%)]\tLoss: 2.783473\n",
      "Train Epoch: 0 [2048/22528 (9%)]\tLoss: 2.249870\n",
      "Train Epoch: 0 [2176/22528 (10%)]\tLoss: 1.996604\n",
      "Train Epoch: 0 [2304/22528 (10%)]\tLoss: 1.329688\n",
      "Train Epoch: 0 [2432/22528 (11%)]\tLoss: 1.334730\n",
      "Train Epoch: 0 [2560/22528 (11%)]\tLoss: 0.956080\n",
      "Train Epoch: 0 [2688/22528 (12%)]\tLoss: 0.973392\n",
      "Train Epoch: 0 [2816/22528 (12%)]\tLoss: 0.778364\n",
      "Train Epoch: 0 [2944/22528 (13%)]\tLoss: 0.738109\n",
      "Train Epoch: 0 [3072/22528 (14%)]\tLoss: 0.585505\n",
      "Train Epoch: 0 [3200/22528 (14%)]\tLoss: 0.584325\n",
      "Train Epoch: 0 [3328/22528 (15%)]\tLoss: 0.551429\n",
      "Train Epoch: 0 [3456/22528 (15%)]\tLoss: 0.477397\n",
      "Train Epoch: 0 [3584/22528 (16%)]\tLoss: 0.526241\n",
      "Train Epoch: 0 [3712/22528 (16%)]\tLoss: 0.596660\n",
      "Train Epoch: 0 [3840/22528 (17%)]\tLoss: 0.429578\n",
      "Train Epoch: 0 [3968/22528 (18%)]\tLoss: 0.397904\n",
      "Train Epoch: 0 [4096/22528 (18%)]\tLoss: 0.419062\n",
      "Train Epoch: 0 [4224/22528 (19%)]\tLoss: 0.369978\n",
      "Train Epoch: 0 [4352/22528 (19%)]\tLoss: 0.395255\n",
      "Train Epoch: 0 [4480/22528 (20%)]\tLoss: 0.409081\n",
      "Train Epoch: 0 [4608/22528 (20%)]\tLoss: 0.443708\n",
      "Train Epoch: 0 [4736/22528 (21%)]\tLoss: 0.348470\n",
      "Train Epoch: 0 [4864/22528 (22%)]\tLoss: 0.390805\n",
      "Train Epoch: 0 [4992/22528 (22%)]\tLoss: 0.338463\n",
      "Train Epoch: 0 [5120/22528 (23%)]\tLoss: 0.360618\n",
      "Train Epoch: 0 [5248/22528 (23%)]\tLoss: 0.350679\n",
      "Train Epoch: 0 [5376/22528 (24%)]\tLoss: 0.344505\n",
      "Train Epoch: 0 [5504/22528 (24%)]\tLoss: 0.339363\n",
      "Train Epoch: 0 [5632/22528 (25%)]\tLoss: 0.374209\n",
      "Train Epoch: 0 [5760/22528 (26%)]\tLoss: 0.358244\n",
      "Train Epoch: 0 [5888/22528 (26%)]\tLoss: 0.292518\n",
      "Train Epoch: 0 [6016/22528 (27%)]\tLoss: 0.326783\n",
      "Train Epoch: 0 [6144/22528 (27%)]\tLoss: 0.359393\n",
      "Train Epoch: 0 [6272/22528 (28%)]\tLoss: 0.379294\n",
      "Train Epoch: 0 [6400/22528 (28%)]\tLoss: 1.413632\n",
      "Train Epoch: 0 [6528/22528 (29%)]\tLoss: 0.314474\n",
      "Train Epoch: 0 [6656/22528 (30%)]\tLoss: 0.340925\n",
      "Train Epoch: 0 [6784/22528 (30%)]\tLoss: 0.331669\n",
      "Train Epoch: 0 [6912/22528 (31%)]\tLoss: 0.343623\n",
      "Train Epoch: 0 [7040/22528 (31%)]\tLoss: 0.287988\n",
      "Train Epoch: 0 [7168/22528 (32%)]\tLoss: 0.310715\n",
      "Train Epoch: 0 [7296/22528 (32%)]\tLoss: 0.336178\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "Caught UnidentifiedImageError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/pavlo/anaconda3/envs/AEenv/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/pavlo/anaconda3/envs/AEenv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/pavlo/anaconda3/envs/AEenv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/pavlo/anaconda3/envs/AEenv/lib/python3.9/site-packages/torchvision/datasets/folder.py\", line 232, in __getitem__\n    sample = self.loader(path)\n  File \"/home/pavlo/anaconda3/envs/AEenv/lib/python3.9/site-packages/torchvision/datasets/folder.py\", line 269, in default_loader\n    return pil_loader(path)\n  File \"/home/pavlo/anaconda3/envs/AEenv/lib/python3.9/site-packages/torchvision/datasets/folder.py\", line 250, in pil_loader\n    img = Image.open(f)\n  File \"/home/pavlo/anaconda3/envs/AEenv/lib/python3.9/site-packages/PIL/Image.py\", line 3030, in open\n    raise UnidentifiedImageError(\nPIL.UnidentifiedImageError: cannot identify image file <_io.BufferedReader name='PetImages/train/Dog/11702.jpg'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13253/237990606.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msince\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13253/3676461852.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m# get the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AEenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AEenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AEenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AEenv/lib/python3.9/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: Caught UnidentifiedImageError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/pavlo/anaconda3/envs/AEenv/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/pavlo/anaconda3/envs/AEenv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/pavlo/anaconda3/envs/AEenv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/pavlo/anaconda3/envs/AEenv/lib/python3.9/site-packages/torchvision/datasets/folder.py\", line 232, in __getitem__\n    sample = self.loader(path)\n  File \"/home/pavlo/anaconda3/envs/AEenv/lib/python3.9/site-packages/torchvision/datasets/folder.py\", line 269, in default_loader\n    return pil_loader(path)\n  File \"/home/pavlo/anaconda3/envs/AEenv/lib/python3.9/site-packages/torchvision/datasets/folder.py\", line 250, in pil_loader\n    img = Image.open(f)\n  File \"/home/pavlo/anaconda3/envs/AEenv/lib/python3.9/site-packages/PIL/Image.py\", line 3030, in open\n    raise UnidentifiedImageError(\nPIL.UnidentifiedImageError: cannot identify image file <_io.BufferedReader name='PetImages/train/Dog/11702.jpg'>\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/exp-1')\n",
    "since = time.time()\n",
    "for epoch in range(EPOCH):\n",
    "    train_loss = train(epoch)\n",
    "    test_loss = test(epoch)\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('test_loss',test_loss, epoch)\n",
    "    torch.save(model.state_dict(), './models/Epoch_{}_Train_loss_{:.4f}_Test_loss_{:.4f}.pth'.format(epoch, train_loss, test_loss))\n",
    "time_elapsed = time.time() - since    \n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
