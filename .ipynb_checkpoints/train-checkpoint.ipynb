{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f39d753d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff983412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "from glob import glob\n",
    "from util import *\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from vae import VAE, ShallowVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6976008d",
   "metadata": {},
   "source": [
    "### Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a38463",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Como era un .py, en esta parte había diversas instrucciones para leer paramétros de entrada\n",
    "    Las hemos eliminado al transformarlo en notebook y no ser necesarias\n",
    "    (pueden verse en el archivo original)\n",
    "\"\"\"\n",
    "torch.manual_seed(1)\n",
    "#Automatización de uso de GPU (si es posible) o CPU\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(1)\n",
    "    is_cuda = True\n",
    "else:\n",
    "    is_cuda = False\n",
    "\n",
    "#Variables globales\n",
    "BATCH_SIZE = 128\n",
    "EPOCH = 20\n",
    "LOG_INTERVAL=1\n",
    "path = 'PetImages/'\n",
    "kwargs = {'num_workers': 3, 'pin_memory': True} if is_cuda else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89878a03",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531e34ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método para hacer un resize a las imágenes y normalizarlas (para que sirvan de entrada a la red)\n",
    "simple_transform = transforms.Compose([transforms.Resize((224,224))\n",
    "                                       ,transforms.ToTensor(), transforms.Normalize([0.48829153, 0.45526633, 0.41688013],[0.25974154, 0.25308523, 0.25552085])])\n",
    "#Carga de imágenes de entrenamiento y de testing\n",
    "train = ImageFolder(path+'train',simple_transform)\n",
    "valid = ImageFolder(path+'valid',simple_transform)\n",
    "\"\"\"Creación de los dataloaders, que se encargarán de cargar los datos en la red\n",
    "   Crearán lotes de imágenes del batch_size indicado anteriormente\n",
    "\"\"\"\n",
    "train_data_gen = torch.utils.data.DataLoader(train,shuffle=True,batch_size=BATCH_SIZE,num_workers=kwargs['num_workers'])\n",
    "valid_data_gen = torch.utils.data.DataLoader(valid,batch_size=BATCH_SIZE,num_workers=kwargs['num_workers'])\n",
    "\n",
    "#Datos relacionados con los datos (convertidos en diccionarios)\n",
    "dataset_sizes = {'train':len(train_data_gen.dataset),'valid':len(valid_data_gen.dataset)}\n",
    "dataloaders = {'train':train_data_gen,'valid':valid_data_gen}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa80a3e6",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f9e312",
   "metadata": {},
   "source": [
    "El modelo es un VAE (Autoencoder Variacional) superficial. En el fichero vae.py están ambos\n",
    "modelos declarados. La diferencia entre ellos es que el superficial tiene un número significativamente inferior de capas interiores para aligerar el peso de la red y el procesado de este.\n",
    "\n",
    "Este VAE superficial tiene 3 bloques: el encoder, el reparametrizador y el decoder\n",
    "El encoder reduce el tamaño de las imágenes pasándolas por diferentes capas convolucionales\n",
    "para extraer las características de las imágenes, hasta convertirlas en un vector.\n",
    "    \n",
    "Este encoder consta de 4 sub-bloques que realizan la misma secuencia: aplican un normalizado en lote, aplican una convolución al resultado y una función ReLu, y se pasa al siguiente bloque (el primero no tiene normalizado). Luego aplica capas full-connected y obtiene valores usados posteriormente.\n",
    "    \n",
    "El reparametrizador normaliza las características obtenidas en el encoder, utilizando para ello una distribución normal y la media y desviación típica obtenidas del propio encoder.\n",
    "\n",
    "El decoder reconstruye las imágenes originales a partir de los datos normalizados obtenidos del reparametrizador. Para ello, aplica dos capas full-connected con su respectiva función ReLu, y luego aplica 4 veces una deconvolución con su respectiva función (ReLu en las 3 primeras y Sigmoide en la última)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dee50bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se declara un modelo que soporta imágenes de 224x224 píxeles RGB (3 canales)\n",
    "model = ShallowVAE(latent_variable_size=500, nc=3, ngf=224, ndf=224, is_cuda=is_cuda)\n",
    "\n",
    "#model = VAE(BasicBlock, [2, 2, 2, 2], latent_variable_size=500, nc=3, ngf=224, ndf=224, is_cuda=is_cuda)\n",
    "\n",
    "if is_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "\"\"\"Se utiliza el Error Cuadrático Medio (Mean Square Error o MSE) para calcular el error de\n",
    "   la red (diferencia entre imagen de entrada e imagen de salida)\n",
    "\"\"\"\n",
    "reconstruction_function = nn.MSELoss()\n",
    "reconstruction_function.size_average = False\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a7384",
   "metadata": {},
   "source": [
    "### Funcion de perdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "283f2843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método para la función de pérdida de la red\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    #Se calcula el MSE\n",
    "    MSE = reconstruction_function(recon_x, x)\n",
    "\n",
    "    # https://arxiv.org/abs/1312.6114 (Appendix B)\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    \n",
    "\"\"\" El KLD es una medida sobre la divergencia entre dos distribuciones probabilisticas\n",
    "    Al usarse la media y la desviación típica para calcular los parámetros, es necesario \n",
    "    aplicar el KLD al MSE para reconducir este error (el MSE sólo calcula la diferencia\n",
    "    entre 2 imágenes, no sus distribuciones)\n",
    "\"\"\"\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "\n",
    "    return MSE + KLD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f1c796",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff22b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "\n",
    "    #Activa diferentes banderas para que la red pueda entrenar\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    batch_idx = 1\n",
    "    #El dataloader carga lotes para meterlos en la red\n",
    "    for data in dataloaders['train']:\n",
    "        #Obtenemos la entrada de la red. El segundo parámetro (la etiqueta) es ignorado\n",
    "        inputs, _ = data\n",
    "\n",
    "        #Se envuelven los datos en una Variable (un Tensor al que se le aplica gradiente)\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "        \n",
    "        #Se resetea el optimizador (para no arrastrar error)\n",
    "        optimizer.zero_grad()\n",
    "        #Se pasan los datos por el modelo y se obtienen imágenes\n",
    "        recon_batch, mu, logvar = model(inputs)\n",
    "        #print(inputs.data.size())\n",
    "        \n",
    "        #Se desnormalizan las imágenes de entrada para que pueda calcularse el error real\n",
    "        inputs.data = unnormalize(inputs.data,[0.48829153, 0.45526633, 0.41688013],[0.25974154, 0.25308523, 0.25552085])\n",
    "\n",
    "        #print(\"input max/min\"+str(inputs.max())+\"  \"+str(inputs.min()))\n",
    "        #print(\"recon input max/min\"+str(recon_batch.max())+\"  \"+str(recon_batch.min()))\n",
    "        \n",
    "        #Se calcula el error producido por la red y se propaga hacia atrás\n",
    "        loss = loss_function(recon_batch, inputs, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(inputs), (len(dataloaders['train'])*128),\n",
    "                100. * batch_idx / len(dataloaders['train']),\n",
    "                loss.data / len(inputs)))\n",
    "        batch_idx+=1\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / (len(dataloaders['train'])*BATCH_SIZE)))\n",
    "    return train_loss / (len(dataloaders['train'])*BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753a317",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54ab6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    #Activa diferentes banderas para que la red pueda evaluarse sin modificarse\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    #El dataloader carga lotes para meterlos en la red\n",
    "    for data in dataloaders['valid']:\n",
    "        #Obtenemos la entrada de la red. El segundo parámetro (la etiqueta) es ignorado\n",
    "        inputs, _ = data\n",
    "\n",
    "        #Se envuelven los datos en una Variable \n",
    "        if torch.cuda.is_available():\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "        #Se pasan los datos por el modelo y se obtienen imágenes\n",
    "        recon_batch, mu, logvar = model(inputs)\n",
    "        #Se desnormalizan las imágenes de entrada para que pueda calcularse el error real\n",
    "        inputs.data = unnormalize(inputs.data,[0.48829153, 0.45526633, 0.41688013],[0.25974154, 0.25308523, 0.25552085])\n",
    "        test_loss += loss_function(recon_batch, inputs, mu, logvar).data\n",
    "        \n",
    "        #Se guardan las imágenes de entrada y las imágenes de salida (ver último apartado)\n",
    "        if((epoch+1)%10==0):\n",
    "            torchvision.utils.save_image(inputs.data, './imgs/Epoch_{}_data.jpg'.format(epoch), nrow=8, padding=2)\n",
    "            torchvision.utils.save_image(recon_batch.data, './imgs/Epoch_{}_recon.jpg'.format(epoch), nrow=8, padding=2)\n",
    "\n",
    "    test_loss /= (len(dataloaders['valid'])*128)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "    return test_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d081748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [128/22528 (1%)]\tLoss: 726.431519\n",
      "Train Epoch: 0 [256/22528 (1%)]\tLoss: 421.336853\n",
      "Train Epoch: 0 [384/22528 (2%)]\tLoss: 259.121948\n",
      "Train Epoch: 0 [512/22528 (2%)]\tLoss: 173.852463\n",
      "Train Epoch: 0 [640/22528 (3%)]\tLoss: 118.367645\n",
      "Train Epoch: 0 [768/22528 (3%)]\tLoss: 76.422195\n",
      "Train Epoch: 0 [896/22528 (4%)]\tLoss: 51.462112\n",
      "Train Epoch: 0 [1024/22528 (5%)]\tLoss: 35.283485\n",
      "Train Epoch: 0 [1152/22528 (5%)]\tLoss: 24.751884\n",
      "Train Epoch: 0 [1280/22528 (6%)]\tLoss: 17.357193\n",
      "Train Epoch: 0 [1408/22528 (6%)]\tLoss: 12.416110\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11422/237990606.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msince\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11422/3676461852.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# wrap them in Variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Crea un fichero \"log\" para almacenar el error de cada época\n",
    "writer = SummaryWriter('runs/exp-1')\n",
    "since = time.time()\n",
    "#El modelo entrena las épocas indicadas, y por cada época de entrenamiento, hace una validación a la red\n",
    "for epoch in range(EPOCH):\n",
    "    train_loss = train(epoch)\n",
    "    test_loss = test(epoch)\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('test_loss',test_loss, epoch)\n",
    "    #Guarda los parámetros de la red en cada iteración (para un posible comeback si la red se desajusta)\n",
    "    torch.save(model.state_dict(), './models/Epoch_{}_Train_loss_{:.4f}_Test_loss_{:.4f}.pth'.format(epoch, train_loss, test_loss))\n",
    "time_elapsed = time.time() - since    \n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd39bd7b",
   "metadata": {},
   "source": [
    "### Problema observados\n",
    "\n",
    "La red es capaz de ajustar de manera sobresaliente en relativamente poco tiempo, sin embargo, hay algún problema a la hora de visualizar las imágenes resultantes. Cuando las imágenes de entrada se guardan, pueden visualizarse en la carpeta correspondiente con buena calidad, pero las imágenes generadas aparecen como imágenes en gris (independientemente de si se reentrena desde 0), por lo que suponemos que es algo relacionado al guardado de estas.\n",
    "\n",
    "Con respecto a la futura generación de imágenes cuando la red está ya entrenada, se necesitaría investigar qué es necesario aportar como entrada a la red para que la genere, pero ya que no es posible visualizar la salida correctamente, no podría comprobarse que funciona bien para estos casos.\n",
    "\n",
    "Esto podría haberse solucionado quizá con suficiente tiempo para investigar y experimentar, pero debido a más proyectos y exámenes, no nos ha sido posible :\"(  (lo sentimos Paco, nos hubiera gustado de verdad poder sacar más tiempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76392326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
